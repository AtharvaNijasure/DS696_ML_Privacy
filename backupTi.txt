
New Summary : model_basic_LR_1_titanicepoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.39 on slice CLASS=0
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.32
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.35
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.66
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.70 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.70
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.29
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.96
New Summary : model_basic_LR_1_titanicepoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.61 on slice CLASS=0
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.32 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.54
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.18
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.91

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.61
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.30
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.50
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.19
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.97

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.41
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.25
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.40
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.32
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.54 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.20 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.94 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.03
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.47
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.03
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.54
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.20
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.13
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.86
New Summary : model_basic_LR_1_titanicepoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.40 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 1.00 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.60
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.25
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.89

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.33
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.40
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.99
New Summary : model_basic_LR_1_titanicepoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.30
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.30
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.66
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.97

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 1.00
New Summary : model_basic_LR_1_titanicepoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.55 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.18 on slice CLASS=1
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.91 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.50
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.09
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.91

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.47
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.11
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.55
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.18
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.89

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.48
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.08
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.86

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.51
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.10
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.91
New Summary : model_basic_LR_1_titanicepoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.55 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.17 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.93 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.51
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.02
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.82

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.55
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.17
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.93

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.09
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.89

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.52
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.84
New Summary : model_basic_LR_1_titanicepoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CLASS=0
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.34
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.98

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.29
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.70 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.40 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.40
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.90

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.70
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.53 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.25 on slice CLASS=0
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.88 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.50
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.14
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.41
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.25
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.82

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.43
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.88

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.20
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.86

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.53
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.18
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.87
New Summary : model_basic_LR_1_titanicepoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.53 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.22 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.87 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.16
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.82

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.07
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.22
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.86

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.51
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.09
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.87
New Summary : model_basic_LR_1_titanicepoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.70 on slice CLASS=0
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.40 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.98 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.43
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.26
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.98

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.70
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.97

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.30
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.40
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.90

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.42
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.98

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.54
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.24
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.59 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.92 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.59
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.25
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.86

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.56
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.21
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.88

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.44
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.24
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.92

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.29
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.45
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.20
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.92
New Summary : model_basic_LR_1_titanicepoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.55 on slice Entire dataset
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.13 on slice Entire dataset
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.55
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.13
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.51
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.06
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.87

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.52
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.11
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.55
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.11
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.51
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.07
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.83
New Summary : model_basic_LR_1_titanicepoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.58 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.21 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 1.00 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.91

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.58
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.21
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.86

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.54
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.15
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.10
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.46
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.16
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.93
New Summary : model_basic_LR_1_titanicepoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.40 on slice CLASS=0
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.30
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.40
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.46
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.53 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.15 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.92 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.12
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.88

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.15
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.09
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.11
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.92

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.51
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.15
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.88
New Summary : model_basic_LR_1_titanicepoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.58
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.17
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.32
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.32
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.68 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.67
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.96
New Summary : model_basic_LR_1_titanicepoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.62 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.32 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.48
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.11
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.38
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.32
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.42
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.28
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.88

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.62
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.32
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.53
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.18
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.87
New Summary : model_basic_LR_1_titanicepoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.50 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.22 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.88 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.15
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.88

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.13
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.08
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.44
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.16
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.44
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.22
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.82
New Summary : model_basic_LR_1_titanicepoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.41 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.66
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.35
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.93

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.33
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.33
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.41
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.82
New Summary : model_basic_LR_1_titanicepoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.33
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.30
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.63 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.31 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 1.00 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.38
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.30
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.96

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.50
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.14
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.48
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.15
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.98

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.53
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.18
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.86

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.63
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 1.00
New Summary : model_basic_LR_1_titanicepoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.13 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.89 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.04
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.13
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.89

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.05
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.88

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.06
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.47
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.08
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.83
New Summary : model_basic_LR_1_titanicepoch_20batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_20batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CLASS=0
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.36 on slice CLASS=0
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.98 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.46
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.25
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.82

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.36
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.98

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.56
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.27
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.96

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.48
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.21
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.40
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.29
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.97
New Summary : model_basic_LR_1_titanicepoch_20batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.67 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.96 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.66
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.33
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.96

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.67
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.96

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.30
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.35
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.33
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.33
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_20batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.53 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.15 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.95 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.48
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.05
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.82

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.51
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.09
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.51
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.15
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.92

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.53
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.11
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.48
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.15
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_20batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.51 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.14 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.89 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.51
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.09
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.89

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.10
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.87

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.12
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.86

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.08
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.82
New Summary : model_basic_LR_1_titanicepoch_30batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_30batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_30batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_30batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.44
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.25
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_30batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.50 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.22 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.86 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.01
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.10
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.44
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.22
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.86

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.45
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.13
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.46
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.16
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.82
New Summary : model_basic_LR_1_titanicepoch_30batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_30batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.30
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_30batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.97 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.97

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.30
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_30batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.70 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.33
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.36
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.38
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.70
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.32
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_30batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.53 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.14 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.93 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.06
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.90

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.05
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.86

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.52
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.12
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.92

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.13
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.93

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.84
New Summary : model_basic_LR_1_titanicepoch_30batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_30batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.70 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.38 on slice CLASS=0
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.53
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.08
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.70
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.32
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.66
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_30batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.70 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.70
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.30
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.29
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.67
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 1.00
New Summary : model_basic_LR_1_titanicepoch_30batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.63 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.30 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.47
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.17
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.89

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.50
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.11
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.89

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.63
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.30
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.51
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.14
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.55
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.17
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.87
New Summary : model_basic_LR_1_titanicepoch_30batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.55 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.19 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.99 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.90

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.55
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.19
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.99

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.47
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.06
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.06
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.82

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.13
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.83
New Summary : model_basic_LR_1_titanicepoch_30batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_30batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.41 on slice CLASS=1
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.32
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.36
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.35
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.36
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.29
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.41
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.32
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.88

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 1.00
New Summary : model_basic_LR_1_titanicepoch_30batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.38 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.91

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.67
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.96
New Summary : model_basic_LR_1_titanicepoch_30batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.52 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.12 on slice CLASS=0
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.50
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.10
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.48
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.12
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.50
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.11
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.86

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.52
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.08
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.52
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.12
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.97
New Summary : model_basic_LR_1_titanicepoch_30batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.55 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.21 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.54
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.18
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.55
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.21
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.10
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.52
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.11
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.04
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_40batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_40batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_40batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.61
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_40batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.53
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.22
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_40batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.59 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.24 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.93 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.58
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.17
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.91

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.45
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.16
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.91

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.44
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.24
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.87

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.59
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.21
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.93

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.54
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.20
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.87
New Summary : model_basic_LR_1_titanicepoch_40batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_40batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.30
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.82
New Summary : model_basic_LR_1_titanicepoch_40batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_40batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CLASS=0
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.47
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.97

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.30
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.32
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.36
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_40batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.58 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.14 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.93 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.51
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.03
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.55
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.13
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.92

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.52
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.93

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.58
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.12
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.89

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.13
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.83
New Summary : model_basic_LR_1_titanicepoch_40batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_40batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.40 on slice CORRECTLY_CLASSIFIED=True
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.47
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.04
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.91

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.30
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.40
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.32
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_40batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.70 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.70
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_40batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.64 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.36 on slice CLASS=0
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.32
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.36
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.64
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.32
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.33
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.36
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.34
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.35
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.90
New Summary : model_basic_LR_1_titanicepoch_40batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.15 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.03
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.12
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.93

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.11
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.88

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.15
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.15
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_40batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_40batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.71 on slice CLASS=0
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.39 on slice CLASS=0
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.97 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.56
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.23
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.97

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.71
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.96

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.45
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.24
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.34
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.40
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.21
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_40batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.60 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.27 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.98 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.48
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.16
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.96

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.58
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.19
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.87

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.44
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.24
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.98

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.60
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.27
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.87

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.51
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.21
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.97
New Summary : model_basic_LR_1_titanicepoch_40batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.54 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.13 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.49
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.08
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.49
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.11
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.52
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.12
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.54
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.13
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.44
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.13
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.96
New Summary : model_basic_LR_1_titanicepoch_40batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.52 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.18 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.90 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.52
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.90

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.10
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.10
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.11
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.42
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.18
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.85
New Summary : model_basic_LR_1_titanicepoch_50batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_50batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CLASS=0
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_50batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_50batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.24
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_50batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.21 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.91 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.41
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.20
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.91

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.43
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.21
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.88

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.04
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.86

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.46
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.19
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.82

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.41
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.21
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.90
New Summary : model_basic_LR_1_titanicepoch_50batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_50batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_50batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_50batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.46
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.22
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_50batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.54 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.19 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.11
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.54
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.19
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.92

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.47
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.13
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.91

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.54
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.18
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.90
New Summary : model_basic_LR_1_titanicepoch_50batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_50batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.40 on slice CORRECTLY_CLASSIFIED=True
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.30
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.30
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.30
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.40
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_50batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.32 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.53 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.22
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.53
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.30
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_50batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CLASS=0
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.38 on slice CLASS=0
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.59
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.21
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.93

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.38
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.66
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.35
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.96

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.33
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.85
New Summary : model_basic_LR_1_titanicepoch_50batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.53 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.18 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.90 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.47
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.16
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.18
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.04
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.90

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.02
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.52
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.86
New Summary : model_basic_LR_1_titanicepoch_50batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_50batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.40 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.96 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.56
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.25
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.96

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.36
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.34
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.62
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.29
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.28
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.40
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_50batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.71 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.96 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.33
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.36
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.29
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.71
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.96

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_50batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.54 on slice Entire dataset
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.21 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.99 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.54
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.12
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.86

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.54
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.10
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.99

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.48
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.21
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.92

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.49
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.07
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.52
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.14
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.90
New Summary : model_basic_LR_1_titanicepoch_50batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.52 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.12 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.52
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.12
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.87

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.12
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.87

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.47
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.07
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.11
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.82

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.51
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.07
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.85
New Summary : model_basic_LR_1_titanicepoch_60batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_60batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50 on slice Entire dataset
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_60batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_60batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.55
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_60batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.67 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.34 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.98 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.52
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.13
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.66
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.33
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.92

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.67
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.34
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.61
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.30
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.98

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.57
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.27
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_60batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_60batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_60batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_60batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.52
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.14
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.93

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_60batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.57 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.25 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.47
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.10
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.46
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.05
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.13
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.57
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.25
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.42
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.20
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.84
New Summary : model_basic_LR_1_titanicepoch_60batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_60batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.38 on slice CORRECTLY_CLASSIFIED=True
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_60batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.38 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_60batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.38 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.53
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.33
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.36
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 1.00

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.38
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.38
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.97

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_60batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.56 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.17 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.96 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.54
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.13
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.56
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.17
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.96

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.02
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.56
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.09
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.49
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.16
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.90
New Summary : model_basic_LR_1_titanicepoch_60batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_60batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.70 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.38 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.96 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.51
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.07
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.96

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.70
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.96

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.32
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.38
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_LR_1_titanicepoch_60batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.70 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.97 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.70
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.70
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.97

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.30
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.38
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.29
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_LR_1_titanicepoch_60batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.55 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.23 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.98 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.50
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.12
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.89

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.50
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.10
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.53
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.17
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.88

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.55
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.15
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.98

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.98
New Summary : model_basic_LR_1_titanicepoch_60batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.56 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.15 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.96 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.51
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.06
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.96

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.03
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.82

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.55
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.15
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.12
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.87

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.56
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.09
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.88
New Summary : model_basic_MLP_1epoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.54
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.00
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.41
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.21
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.32
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.00
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.24
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.00
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.42
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.19
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.21
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.01
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CLASS=0
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.50
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.16
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.92

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.00
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CLASS=0
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.24
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.44
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.12
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.00
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.55
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_20batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_20batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CLASS=0
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.16
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_20batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.54 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.86 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.54
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.23
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.86

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.32
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_30batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_30batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_30batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_30batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_30batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_30batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_30batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50 on slice Entire dataset
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_30batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_30batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.95 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.61
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.24
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.32
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_30batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.22
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.00
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_30batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_30batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_30batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_30batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.46
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.22
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_30batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.00
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_30batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_30batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_30batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.42 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.95 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.29
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.42
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_30batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.45 on slice Entire dataset
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.24
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_30batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.32
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.00
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_40batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CLASS=0
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.24
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_40batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_40batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_40batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.25
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_40batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.41
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.32
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.32
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_40batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.44
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.12
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.00
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.47
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.21
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_40batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_50batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CLASS=0
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.53
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_50batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_50batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.61
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.25
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50 on slice Entire dataset
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.32
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_50batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.54
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.22
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_50batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.44
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.25
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_50batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.35
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.27
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_60batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_60batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CLASS=0
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_60batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_60batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.46
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.22
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_60batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.32
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_60batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_60batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_60batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_60batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.42
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.18
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_60batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.15
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_60batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_60batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_60batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_60batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.52
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.22
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_60batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.36
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.26
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_60batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_60batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_60batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_1epoch_60batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.54
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.22
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.85

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_1epoch_60batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.48
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.32
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.43
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.18
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.62
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.23
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.55
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.22
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.32
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.36
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.25
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.00
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.39 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CLASS=0
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.24
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CLASS=0
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.53
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.22
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CLASS=0
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.53
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_10batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CLASS=0
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.42
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.19
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_32verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.69 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.69
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.50
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.00
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50 on slice Entire dataset
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=True
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.44 on slice Entire dataset
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.44
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.24
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_64verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.47 on slice Entire dataset
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.84 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.47
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.14
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.84

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CLASS=1
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.69
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CORRECTLY_CLASSIFIED=False
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95 on slice CORRECTLY_CLASSIFIED=False

Best-performing attacks over slice: "Entire dataset"
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an AUC of 0.45
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved an advantage of 0.23
  RANDOM_FOREST (with 1047 training and 262 test examples) achieved a positive predictive value of 0.83

Best-performing attacks over slice: "CLASS=0"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.68
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an AUC of 0.31
  RANDOM_FOREST (with 648 training and 167 test examples) achieved an advantage of 0.37
  RANDOM_FOREST (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an AUC of 0.69
  RANDOM_FOREST (with 399 training and 95 test examples) achieved an advantage of 0.39
  RANDOM_FOREST (with 399 training and 95 test examples) achieved a positive predictive value of 0.95
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_128verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94 on slice Entire dataset

Best-performing attacks over slice: "Entire dataset"
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an AUC of 0.61
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved an advantage of 0.25
  K_NEAREST_NEIGHBORS (with 1047 training and 262 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=0"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.32
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an AUC of 0.68
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved an advantage of 0.37
  K_NEAREST_NEIGHBORS (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an AUC of 0.31
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved an advantage of 0.39
  K_NEAREST_NEIGHBORS (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50 on slice CLASS=0
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02 on slice Entire dataset
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81 on slice CLASS=1

Best-performing attacks over slice: "Entire dataset"
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an AUC of 0.49
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved an advantage of 0.02
  THRESHOLD_ATTACK (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an AUC of 0.50
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved an advantage of 0.00
  THRESHOLD_ATTACK (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68 on slice CORRECTLY_CLASSIFIED=True
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CORRECTLY_CLASSIFIED=True

Best-performing attacks over slice: "Entire dataset"
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an AUC of 0.50
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved an advantage of 0.00
  LOGISTIC_REGRESSION (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=1"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an AUC of 0.68
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved an advantage of 0.37
  LOGISTIC_REGRESSION (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an AUC of 0.31
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved an advantage of 0.39
  LOGISTIC_REGRESSION (with 399 training and 95 test examples) achieved a positive predictive value of 0.81
New Summary : model_basic_MLP_Deep_10_Titanicepoch_20batch_size_256verbose_1optim_fn_adam.sav
 model params :bat , summary : Best-performing attacks over all slices
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69 on slice CLASS=0
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39 on slice CLASS=1
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94 on slice CLASS=0

Best-performing attacks over slice: "Entire dataset"
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an AUC of 0.32
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 1047 training and 262 test examples) achieved a positive predictive value of 0.80

Best-performing attacks over slice: "CLASS=0"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.69
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CLASS=1"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=True"
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an AUC of 0.68
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved an advantage of 0.37
  MULTI_LAYERED_PERCEPTRON (with 648 training and 167 test examples) achieved a positive predictive value of 0.94

Best-performing attacks over slice: "CORRECTLY_CLASSIFIED=False"
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an AUC of 0.31
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved an advantage of 0.39
  MULTI_LAYERED_PERCEPTRON (with 399 training and 95 test examples) achieved a positive predictive value of 0.81